---
title: "5243_Project1"
author: "QIUJUN ZHANG"
date: "2026-02-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# Load packages and dataset
library(tidyverse)
library(lubridate)
library(readr)
library(stringr)
library(janitor)
library(glue)

raw_path <- "initial_data.csv"
if (!file.exists(raw_path)) raw_path <- "/mnt/data/initial_data.csv"

out_dir <- "data/processed"
if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE)
```

```{r}
# -----------------------------
# 1) Read raw data (as character to *detect* type issues)
# -----------------------------
df_raw <- read_csv(
  raw_path,
  col_types = cols(
    country_name = col_character(),
    country_iso2 = col_character(),
    week = col_character(),
    category = col_character(),
    weekly_rank = col_character(),
    show_title = col_character(),
    season_title = col_character(),
    cumulative_weeks_in_top_10 = col_character()
  ),
  show_col_types = FALSE
) %>%
  clean_names()
```

```{r}
# -----------------------------
# 2) Uniform formatting (strings)
#    - trim/squish whitespace
#    - convert "" to NA
# -----------------------------
df_std <- df_raw %>%
  mutate(across(where(is.character), ~ str_squish(.x))) %>%
  mutate(across(where(is.character), ~ na_if(.x, "")))
```

```{r}
# -----------------------------
# 3) Filter to Films only (NOT TV)
#    - standardize labels first (case/whitespace)
# -----------------------------
df_films_raw <- df_std %>%
  mutate(category = str_to_title(category)) %>%   # e.g., "films" -> "Films"
  filter(category == "Films")
```

```{r}
# -----------------------------
# 4) Detect & rectify inconsistencies (data types, labels)
#    - Parse week as Date
#    - Parse ranks/weeks as integer
#    - Standardize ISO2 formatting
#    - Track parse failures (type inconsistencies)
# -----------------------------
df_films_typed <- df_films_raw %>%
  mutate(
    country_iso2 = str_to_upper(country_iso2),
    week_date = ymd(week),

    weekly_rank_int = parse_integer(weekly_rank),
    cum_weeks_int   = parse_integer(cumulative_weeks_in_top_10)
  )

# ---- Type inconsistency diagnostics (useful for report) ----
type_issues <- list(
  week_parse_fail = df_films_typed %>% filter(is.na(week_date) & !is.na(week)) %>% nrow(),
  weekly_rank_parse_fail = df_films_typed %>% filter(is.na(weekly_rank_int) & !is.na(weekly_rank)) %>% nrow(),
  cum_weeks_parse_fail = df_films_typed %>% filter(is.na(cum_weeks_int) & !is.na(cumulative_weeks_in_top_10)) %>% nrow()
)
print(type_issues)
```

```{r}
# -----------------------------
# 5) Handle missing values
#    Your rule for Films:
#      - season_title NULL/NA -> "Movie"
#    For critical fields:
#      - drop rows missing week_date, weekly_rank_int, show_title
#    ALSO: create week labels ("week 1", "week 2", ...)
# -----------------------------
df_films_miss <- df_films_typed %>%
  mutate(
    season_title = if_else(is.na(season_title), "Movie", season_title)
  ) %>%
  filter(
    !is.na(week_date),
    !is.na(weekly_rank_int),
    !is.na(show_title)
  ) %>%
  mutate(
    week_num   = dense_rank(week_date),              # 1,2,3,... by chronological week
    week_label = paste0("week ", week_num)           # "week 1", "week 2", ...
  )
```

```{r}
# -----------------------------
# 6) Address duplicates (if applicable)
#    - Define a natural key and de-duplicate
# -----------------------------
key_cols <- c(
  "country_iso2", "week_date", "category", "weekly_rank_int",
  "show_title", "season_title", "cum_weeks_int"
)

dup_table <- df_films_miss %>%
  count(across(all_of(key_cols)), name = "n") %>%
  filter(n > 1)

message(glue("Duplicate key groups found: {nrow(dup_table)}"))
# If duplicates exist, keep the first occurrence (or change rule if you prefer)
df_films_nodup <- df_films_miss %>%
  distinct(across(all_of(key_cols)), .keep_all = TRUE)
```


```{r}
# -----------------------------
# 8) Netflix-specific rule: weekly_rank must be 1–10
# -----------------------------
bad_weekly_rank <- df_films_nodup %>%
  filter(is.na(weekly_rank_int) | weekly_rank_int < 1 | weekly_rank_int > 10)

if (nrow(bad_weekly_rank) > 0) {
  warning(glue("Found {nrow(bad_weekly_rank)} rows with weekly_rank outside 1–10. Inspect `bad_weekly_rank`."))
} else {
  message("weekly_rank check PASSED: all values are within 1–10.")
}
```

```{r}
# -----------------------------
# 9) Final tidy dataset (choose final column names)
# -----------------------------
df_clean <- df_films_nodup %>%
  transmute(
    country_name,
    country_iso2,
    week = week_num,            # <- numeric week index
    week_date,                  # <- keep actual date for reference
    category,
    weekly_rank = weekly_rank_int,
    show_title,
    season_title,
    cumulative_weeks_in_top_10 = cum_weeks_int
  )

```

```{r}
# -----------------------------
# 10) Save outputs
# -----------------------------
write_csv(df_clean, file.path(out_dir, "netflix_films_clean.csv"))

# Quick summary for report
cleaning_summary <- list(
  n_raw = nrow(df_raw),
  n_films_before_clean = nrow(df_films_raw),
  n_films_after_clean = nrow(df_clean),
  missing_season_title_after = sum(is.na(df_clean$season_title)),
  weekly_rank_range = range(df_clean$weekly_rank, na.rm = TRUE)
)
print(cleaning_summary)

```

```{r}
# -----------------------------
# 11) Preview final dataset (first few rows)
# -----------------------------
out_path <- file.path(out_dir, "netflix_films_clean.csv")

cat("Working directory:", getwd(), "\n")
cat("Cleaned dataset saved to:", normalizePath(out_path, winslash = "/"), "\n\n")

cat("First 10 rows of df_clean (sorted):\n")
print(df_clean %>% arrange(week_date, country_iso2, weekly_rank) %>% head(10))

cat("\nWeek number mapping (first 10):\n")
print(df_clean %>% distinct(week, week_date) %>% arrange(week_date) %>% head(10))

cat("\nColumn types (glimpse):\n")
dplyr::glimpse(df_clean)
```

